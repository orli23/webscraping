{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import csv\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'my_spider'\n",
    "\n",
    "    def start_requests(self):\n",
    "        # specify the main page URL\n",
    "        url = 'https://nodesk.co/remote-jobs/'\n",
    "        yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # from mainpage go into subpage\n",
    "        # URL = https://nodesk.co/remote-jobs/\n",
    "        # this scrape all the featured posts on the website\n",
    "\n",
    "        # follow links for each job category\n",
    "        for href in response.css('div.cf.center-l.mw14-l.search-ui div a::attr(href)').getall()[9:-5]:\n",
    "            url = response.urljoin(href)\n",
    "            yield scrapy.Request(url, callback=self.parse_job_category)\n",
    "\n",
    "    def parse_job_category(self, response):\n",
    "        # scrape job posts from each category\n",
    "        # follow links for each job post in the category\n",
    "        for job_post_url in response.css('h2.f8.f7-ns.fw6.lh-title.mb1.mt0 a::attr(href)').getall():\n",
    "            # extract job details\n",
    "            # extract company name\n",
    "            company_name = response.css('div.dtc-ns.pl3-s.pl3-ns.v-top h3 * ::text').getall()\n",
    "            # extract job title\n",
    "            job_title = response.css('div.dtc-ns.pl3-s.pl3-ns.v-top h2 * ::text').getall()\n",
    "            # extract country\n",
    "            country = response.css('div.inline-flex.items-center.flex-wrap.flex-nowrap-l.mb1-l h5 * ::text').getall()\n",
    "            # extract job type\n",
    "            job_type = response.css('div.flex.inline-flex-s.inline-flex-ns.items-center.mr3-s.mr3-m.mr6-l.mv1.mv0-l.nowrap h4 * ::text').getall()\n",
    "            # extract industries\n",
    "            industries = response.css('div.inline-flex.items-center.mr3.mr6-l.mv1.mv0-l h4 * ::text').getall()\n",
    "            # extract salary\n",
    "            salary_els = response.css('div.inline-flex.items-center.mv1.mv0-l h4.f9.fw4.grey-700.mv0::text, div.inline-flex.items-center.mv1.mv0-l h4.f9.fw4.grey-900.mv0::text')\n",
    "            if salary_els:\n",
    "                salary = salary_els[0].get()\n",
    "            else:\n",
    "                salary = '0'\n",
    "            # extract skills\n",
    "            skills = response.css('div.mt2.mt3-s.mt3-l li * ::text').getall()\n",
    "\n",
    "            yield scrapy.Request(job_post_url, callback=self.parse_job_post, cb_kwargs=dict(\n",
    "                company_name=company_name,\n",
    "                job_title=job_title,\n",
    "                job_type=job_type,\n",
    "                industries=industries,\n",
    "                salary=salary,\n",
    "                skills=skills,\n",
    "            ))\n",
    "\n",
    "    def parse_job_post(self, response, company_name, job_title, job_type, industries, salary, skills):\n",
    "        # create a dictionary to store scraped info\n",
    "        scraped_info = {\n",
    "            'URL': response.url,\n",
    "            'company_name': company_name,\n",
    "            'job_title': job_title,\n",
    "            'job_type': job_type,\n",
    "            'industries': industries,\n",
    "            'salary': salary,\n",
    "            'skills': skills}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import csv\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'my_spider'\n",
    "\n",
    "    def start_requests(self):\n",
    "        # specify the main page URL\n",
    "        url = 'https://nodesk.co/remote-jobs/'\n",
    "        yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # from mainpage go into subpage\n",
    "        # URL = https://nodesk.co/remote-jobs/\n",
    "        # this scrape all the featured posts on the website\n",
    "\n",
    "        # follow links for each job category\n",
    "        for href in response.css('div.cf.center-l.mw14-l.search-ui div a::attr(href)').getall()[9:-5]:\n",
    "            url = response.urljoin(href)\n",
    "            yield scrapy.Request(url, callback=self.parse_job_category)\n",
    "       \n",
    "    def parse_job_category(self, response):\n",
    "        # scrape job posts from each category\n",
    "        # follow links for each job post in the category\n",
    "        for job_post_url in response.css('h2.f8.f7-ns.fw6.lh-title.mb1.mt0 a::attr(href)').getall():\n",
    "            # call a separate method to scrape the company name for each job posting\n",
    "            yield scrapy.Request(url=job_post_url, callback=self.parse_company_name)\n",
    "\n",
    "    def parse_company_name(self, response):\n",
    "        # extract company name\n",
    "        company_name = response.css('div.dtc-ns.pl3-s.pl3-ns.v-top h3 * ::text').getall()\n",
    "        company_name = (', '.join(company_name))\n",
    "        print(company_name)\n",
    "       \n",
    "        # extract job title\n",
    "        job_title = response.css('div.dtc-ns.pl3-s.pl3-ns.v-top h2 * ::text').getall()\n",
    "        job_title = (', '.join(job_title))\n",
    "\n",
    "        print(job_title)\n",
    "        # extract country\n",
    "        country = response.css('div.inline-flex.items-center.flex-wrap.flex-nowrap-l.mb1-l h5 * ::text').getall()\n",
    "        country = (', '.join(country))\n",
    "\n",
    "        print(country)\n",
    "        # extract job type\n",
    "        job_type = response.css('div.flex.inline-flex-s.inline-flex-ns.items-center.mr3-s.mr3-m.mr6-l.mv1.mv0-l.nowrap h4 * ::text').getall()\n",
    "        job_type = (', '.join(job_type))\n",
    "   \n",
    "         print(job_type)\n",
    "        # extract industries\n",
    "        industries = response.css('div.inline-flex.items-center.mr3.mr6-l.mv1.mv0-l h4 * ::text').getall()\n",
    "        industries = (', '.join(industries))\n",
    "\n",
    "        print(industries)\n",
    "        # extract salary\n",
    "        salary_els = response.css('div.inline-flex.items-center.mv1.mv0-l h4.f9.fw4.grey-700.mv0::text, div.inline-flex.items-center.mv1.mv0-l h4.f9.fw4.grey-900.mv0::text')\n",
    "        if salary_els:\n",
    "            salary = salary_els[0].get()\n",
    "        else:\n",
    "             salary = '0'\n",
    "        salary = (', '.join(salary))\n",
    "        print(salary)\n",
    "\n",
    "        # extract skills\n",
    "            skills = response.css('div.mt2.mt3-s.mt3-l li * ::text').getall()\n",
    "            skills = (', '.join(skills))\n",
    "            print(skills)\n",
    "            \n",
    "            for item in zip([job_post_url], [company_name], [job_title], [job_type], [industries], [salary], [skills]):\n",
    "                # create a dictionary to store scraped info\n",
    "                scraped_info = {\n",
    "                    'URL': item[0],\n",
    "                    'company_name': item[1],\n",
    "                    'job_title': item[2],\n",
    "                    'job_type': item[3],\n",
    "                    'industries': item[4],\n",
    "                    'salary': item[5],\n",
    "                    'skills': item[6]\n",
    "                }\n",
    "                yield scraped_info\n",
    "\n",
    "# run the spider and save the output to a CSV file\n",
    "process = CrawlerProcess(settings={\n",
    "    'FEED_FORMAT': 'csv',\n",
    "    'FEED_URI': 'output.csv',\n",
    "    'LOG_ENABLED': False\n",
    "})\n",
    "process.crawl(MySpider)\n",
    "process.start()\n",
    "process.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2904ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "import csv\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'my_spider'\n",
    "    start_urls = ['https://nodesk.co/remote-jobs/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        #extract the url for each job category\n",
    "        category_urls = response.css('div.cf.center-l.mw14-l.search-ui div a::attr(href)').getall()[9:-5]\n",
    "\n",
    "        # Visit each category page and call the parse_category method\n",
    "        for url in category_urls:\n",
    "            yield scrapy.Request(url, callback=self.parse_category)\n",
    "\n",
    "    def parse_category(self, response):\n",
    "        # Extract the URLs for each job post on the category page\n",
    "        job_post_urls = response.css('h2.f8.f7-ns.fw6.lh-title.mb1.mt0 a::attr(href)').getall()\n",
    "\n",
    "        # Visit each job post URL and call the parse_job_post method\n",
    "        for url in job_post_urls:\n",
    "            yield scrapy.Request(url, callback=self.parse_job_post, cb_kwargs=dict(url=url))\n",
    "\n",
    "    def parse_job_post(self, response, url):\n",
    "        # Extract the information you need from the job post page\n",
    "        # extract job details\n",
    "            # extract company name\n",
    "            company_name = response.css('div.dtc-ns.pl3-s.pl3-ns.v-top h3 * ::text').getall()\n",
    "            # extract job title\n",
    "            job_title = response.css('div.dtc-ns.pl3-s.pl3-ns.v-top h2 * ::text').getall()\n",
    "            # extract country\n",
    "            country = response.css('div.inline-flex.items-center.flex-wrap.flex-nowrap-l.mb1-l h5 * ::text').getall()\n",
    "            # extract job type\n",
    "            job_type = response.css('div.flex.inline-flex-s.inline-flex-ns.items-center.mr3-s.mr3-m.mr6-l.mv1.mv0-l.nowrap h4 * ::text').getall()\n",
    "            # extract industries\n",
    "            industries = response.css('div.inline-flex.items-center.mr3.mr6-l.mv1.mv0-l h4 * ::text').getall()\n",
    "            # extract salary\n",
    "            salary_els = response.css('div.inline-flex.items-center.mv1.mv0-l h4.f9.fw4.grey-700.mv0::text, div.inline-flex.items-center.mv1.mv0-l h4.f9.fw4.grey-900.mv0::text')\n",
    "            if salary_els:\n",
    "                salary = salary_els[0].get()\n",
    "            else:\n",
    "                salary = '0'\n",
    "            # extract skills\n",
    "            skills = response.css('div.mt2.mt3-s.mt3-l li * ::text').getall()\n",
    "            \n",
    "            # Yield a dictionary with the extracted information\n",
    "            scraped_info =  {\n",
    "                'url': url,\n",
    "                'company': company_name,\n",
    "                'job_title': job_title,\n",
    "                'job_type': job_type,\n",
    "                'country': country,\n",
    "                'industry': industries,\n",
    "                'salary': salary,\n",
    "                'skills': skills\n",
    "            }\n",
    "            yield scraped_info\n",
    "\n",
    "# run the spider and save the output to a CSV file\n",
    "process = CrawlerProcess(settings={\n",
    "    'FEED_FORMAT': 'csv',\n",
    "    'FEED_URI': 'output.csv',\n",
    "    'LOG_ENABLED': False\n",
    "})\n",
    "process.crawl(MySpider)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f6f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
